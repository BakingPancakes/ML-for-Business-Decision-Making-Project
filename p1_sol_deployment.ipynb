{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a18846-88ee-4d19-93ec-77b47e82dda1",
   "metadata": {
    "id": "32a18846-88ee-4d19-93ec-77b47e82dda1"
   },
   "source": [
    "This is a minimal code to see how to save a final model, plus additional information, that can be used later by Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d969a5a-3b20-45f7-a06b-ad840ad5864e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "7d969a5a-3b20-45f7-a06b-ad840ad5864e",
    "outputId": "796fde78-6c9f-4a64-df73-6079150e1ff0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell creates the final model, trained with the entire dataset (X, y)\n",
    "# In a more complex case (like that of the assignment), the final model would be an entire pipeline (with preprocessing)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "import pickle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import xgboost as xgb\n",
    "\n",
    "TRAINING_DATA_PATH = Path('dataset', 'bank_06.pkl')\n",
    "raw_data = pd.read_pickle(TRAINING_DATA_PATH)\n",
    "RANDOM_STATE_ID = 100577770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06fbd070-8377-4517-b3cb-dd0a277b58ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06fbd070-8377-4517-b3cb-dd0a277b58ec",
    "outputId": "9a81a095-eca5-473c-e181-0889ee817137"
   },
   "outputs": [],
   "source": [
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'previous', 'pdays_duration', 'prev_contacted']\n",
    "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "class PdaysTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.median_pdays = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        known_pdays = X.loc[X['pdays'] != -1, 'pdays']\n",
    "        self.median_pdays = known_pdays.median() if len(known_pdays) > 0 else 0\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['prev_contacted'] = (X['pdays'] != -1).astype(int)\n",
    "        X['pdays_duration'] = X['pdays'].replace(-1, self.median_pdays)\n",
    "        X.drop('pdays', axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "# Column transformer for scaling and encoding\n",
    "column_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_params = {\n",
    "    'max_depth' : 7, \n",
    "    'learning_rate': 0.0683962886025413,\n",
    "    'n_estimators' : 181\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b8fa539",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('pdays_transform', PdaysTransformer()),\n",
    "    ('preprocessor', column_processor),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        max_depth=best_params['max_depth'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        random_state=RANDOM_STATE_ID\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84c092e4",
   "metadata": {
    "id": "84c092e4"
   },
   "outputs": [],
   "source": [
    "# Here, we pack and save into a joblib file, the final model, plus information about the numerical and categorical features\n",
    "pack = {\n",
    "  \"pipeline\" : full_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae56063d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae56063d",
    "outputId": "9599dede-6b37-4d11-ef80-4dec57fa7062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pack_for_streamlit.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pack, \"pack_for_streamlit.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
