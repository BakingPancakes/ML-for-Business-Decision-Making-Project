{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b926ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zavier Morales\n",
    "# Edouard Mason\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# Define global variables & import data\n",
    "\n",
    "RANDOM_STATE_ID = 100577770\n",
    "\n",
    "TRAINING_DATA_PATH = Path('dataset', 'bank_06.pkl')\n",
    "COMPETITION_DATA_PATH = Path('dataset', 'bank_competition.pkl')\n",
    "\n",
    "training_times = {}\n",
    "tuning_times = {}\n",
    "prediction_times = {}\n",
    "\n",
    "raw_data = pd.read_pickle(TRAINING_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcefc7",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ed199",
   "metadata": {},
   "source": [
    "Our goal in EDA is to ensure the following about our dataset:\n",
    "* All variables are in numerical format.\n",
    "* There are no missing values in our dataset.\n",
    "* Our dataset is well balanced (this is a classification problem since we are predicting whether a customer will subscribe or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ca3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      " (11000, 17)\n",
      "\n",
      "First few rows:\n",
      "    age         job  marital  education default  balance housing loan  contact  \\\n",
      "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
      "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
      "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
      "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
      "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
      "\n",
      "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
      "0    5   may      1042         1     -1         0  unknown     yes  \n",
      "1    5   may      1467         1     -1         0  unknown     yes  \n",
      "2    5   may      1389         1     -1         0  unknown     yes  \n",
      "3    5   may       579         1     -1         0  unknown     yes  \n",
      "4    5   may       673         2     -1         0  unknown     yes  \n",
      "\n",
      "List of columns:\n",
      " Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'deposit'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Target variable:\n",
      " 0    yes\n",
      "1    yes\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "Name: deposit, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# quick look at our dataset to help us determine what to do first (probably convert categorical to numerical)\n",
    "print(\"Shape of the dataset:\\n\", raw_data.shape)\n",
    "print(\"\\nFirst few rows:\\n\",raw_data.head())\n",
    "print(\"\\nList of columns:\\n\",raw_data.columns)\n",
    "print(\"\\n\\n\\nTarget variable:\\n\",raw_data['deposit'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9022e2",
   "metadata": {},
   "source": [
    "Here we are finding the cardinality & data types of variables in order to determine which variables are object-like vs already numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1188cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            76\n",
      "job            12\n",
      "marital         3\n",
      "education       4\n",
      "default         2\n",
      "balance      3783\n",
      "housing         2\n",
      "loan            2\n",
      "contact         3\n",
      "day            31\n",
      "month          12\n",
      "duration     1423\n",
      "campaign       36\n",
      "pdays         472\n",
      "previous       34\n",
      "poutcome        4\n",
      "deposit         2\n",
      "dtype: int64\n",
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "deposit      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cardinality of variables\n",
    "unique_counts = raw_data.nunique()\n",
    "print(unique_counts)\n",
    "print(raw_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9c6b5",
   "metadata": {},
   "source": [
    "We use one-hot encoding to create new columns for the categorical variables we just identified.\n",
    "We also check if there are any missing values per column, and luckily we find that there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "012a3f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  balance  day  duration  campaign  pdays  previous deposit  \\\n",
      "0       59     2343    5      1042         1     -1         0     yes   \n",
      "1       56       45    5      1467         1     -1         0     yes   \n",
      "2       41     1270    5      1389         1     -1         0     yes   \n",
      "3       55     2476    5       579         1     -1         0     yes   \n",
      "4       54      184    5       673         2     -1         0     yes   \n",
      "...    ...      ...  ...       ...       ...    ...       ...     ...   \n",
      "11157   33        1   20       257         1     -1         0      no   \n",
      "11158   39      733   16        83         4     -1         0      no   \n",
      "11159   32       29   19       156         2     -1         0      no   \n",
      "11160   43        0    8         9         2    172         5      no   \n",
      "11161   34        0    9       628         1     -1         0      no   \n",
      "\n",
      "       job_admin.  job_blue-collar  ...  month_jun  month_mar  month_may  \\\n",
      "0               1                0  ...          0          0          1   \n",
      "1               1                0  ...          0          0          1   \n",
      "2               0                0  ...          0          0          1   \n",
      "3               0                0  ...          0          0          1   \n",
      "4               1                0  ...          0          0          1   \n",
      "...           ...              ...  ...        ...        ...        ...   \n",
      "11157           0                1  ...          0          0          0   \n",
      "11158           0                0  ...          1          0          0   \n",
      "11159           0                0  ...          0          0          0   \n",
      "11160           0                0  ...          0          0          1   \n",
      "11161           0                0  ...          0          0          0   \n",
      "\n",
      "       month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
      "0              0          0          0                 0               0   \n",
      "1              0          0          0                 0               0   \n",
      "2              0          0          0                 0               0   \n",
      "3              0          0          0                 0               0   \n",
      "4              0          0          0                 0               0   \n",
      "...          ...        ...        ...               ...             ...   \n",
      "11157          0          0          0                 0               0   \n",
      "11158          0          0          0                 0               0   \n",
      "11159          0          0          0                 0               0   \n",
      "11160          0          0          0                 1               0   \n",
      "11161          0          0          0                 0               0   \n",
      "\n",
      "       poutcome_success  poutcome_unknown  \n",
      "0                     0                 1  \n",
      "1                     0                 1  \n",
      "2                     0                 1  \n",
      "3                     0                 1  \n",
      "4                     0                 1  \n",
      "...                 ...               ...  \n",
      "11157                 0                 1  \n",
      "11158                 0                 1  \n",
      "11159                 0                 1  \n",
      "11160                 0                 0  \n",
      "11161                 0                 1  \n",
      "\n",
      "[11000 rows x 52 columns]\n",
      "\n",
      "Columns in the DataFrame:\n",
      "\n",
      " Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'deposit', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
      "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
      "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
      "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
      "       'education_primary', 'education_secondary', 'education_tertiary',\n",
      "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
      "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
      "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
      "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
      "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
      "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
      "       'poutcome_unknown'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "\n",
      "    age  balance  day  duration  campaign  pdays  previous deposit  job_admin.  \\\n",
      "0   59     2343    5      1042         1     -1         0     yes           1   \n",
      "1   56       45    5      1467         1     -1         0     yes           1   \n",
      "2   41     1270    5      1389         1     -1         0     yes           0   \n",
      "3   55     2476    5       579         1     -1         0     yes           0   \n",
      "4   54      184    5       673         2     -1         0     yes           1   \n",
      "\n",
      "   job_blue-collar  ...  month_jun  month_mar  month_may  month_nov  \\\n",
      "0                0  ...          0          0          1          0   \n",
      "1                0  ...          0          0          1          0   \n",
      "2                0  ...          0          0          1          0   \n",
      "3                0  ...          0          0          1          0   \n",
      "4                0  ...          0          0          1          0   \n",
      "\n",
      "   month_oct  month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "0          0          0                 0               0                 0   \n",
      "1          0          0                 0               0                 0   \n",
      "2          0          0                 0               0                 0   \n",
      "3          0          0                 0               0                 0   \n",
      "4          0          0                 0               0                 0   \n",
      "\n",
      "   poutcome_unknown  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "\n",
      "Missing values per column:\n",
      "\n",
      " age                    0\n",
      "balance                0\n",
      "day                    0\n",
      "duration               0\n",
      "campaign               0\n",
      "pdays                  0\n",
      "previous               0\n",
      "deposit                0\n",
      "job_admin.             0\n",
      "job_blue-collar        0\n",
      "job_entrepreneur       0\n",
      "job_housemaid          0\n",
      "job_management         0\n",
      "job_retired            0\n",
      "job_self-employed      0\n",
      "job_services           0\n",
      "job_student            0\n",
      "job_technician         0\n",
      "job_unemployed         0\n",
      "job_unknown            0\n",
      "marital_divorced       0\n",
      "marital_married        0\n",
      "marital_single         0\n",
      "education_primary      0\n",
      "education_secondary    0\n",
      "education_tertiary     0\n",
      "education_unknown      0\n",
      "default_no             0\n",
      "default_yes            0\n",
      "housing_no             0\n",
      "housing_yes            0\n",
      "loan_no                0\n",
      "loan_yes               0\n",
      "contact_cellular       0\n",
      "contact_telephone      0\n",
      "contact_unknown        0\n",
      "month_apr              0\n",
      "month_aug              0\n",
      "month_dec              0\n",
      "month_feb              0\n",
      "month_jan              0\n",
      "month_jul              0\n",
      "month_jun              0\n",
      "month_mar              0\n",
      "month_may              0\n",
      "month_nov              0\n",
      "month_oct              0\n",
      "month_sep              0\n",
      "poutcome_failure       0\n",
      "poutcome_other         0\n",
      "poutcome_success       0\n",
      "poutcome_unknown       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoding object-type variables (except for deposit, which is our target variable)\n",
    "df_encoded = pd.get_dummies(raw_data, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'])\n",
    "print(df_encoded)\n",
    "\n",
    "#Converting all boolean columns to integers (1 for True, 0 for False)\n",
    "df_encoded[df_encoded.select_dtypes(include=['bool']).columns] = df_encoded.select_dtypes(include=['bool']).astype(int)\n",
    "print(\"\\nColumns in the DataFrame:\\n\\n\",df_encoded.columns)\n",
    "print(\"\\n\\nFirst few rows of the DataFrame:\\n\\n\",df_encoded.head())\n",
    "\n",
    "#Checking the number of missing values per column\n",
    "missing_values = df_encoded.isnull().sum()\n",
    "print(\"\\nMissing values per column:\\n\\n\", missing_values)   #We get 0 for each column so we have no missing values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0e85b",
   "metadata": {},
   "source": [
    "The issue with the *pdays* variable is that the variable encodes multiple meanings: the duration between contacts and the status of the contact. Instead, we must figure out a way to modify *pdays* or create new columns to preserve the different meanings while maintaining that 1) the variables are numerical and 2) only encodes one meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e326819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8203\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where pdays == -1\n",
    "count_minus1 = (raw_data['pdays'] == -1).sum()\n",
    "\n",
    "print(count_minus1)\n",
    "\n",
    "# We see that there are 8203 where pdays = -1, that is where we have no info or contact. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585a887",
   "metadata": {},
   "source": [
    "Our method is to create a new dummy variable *prev_contacted* where 1 means the value for *pdays* was not -1, and 0 where it was -1. This dummy variable only encodes the status of the contact with the customer, and satisfies our two criteria above (numerical and encodes one meaning).\n",
    "\n",
    "We then replace *pdays* with *pdays_duration* where all values that were originally -1 are instead the median of all positive *pdays* values. This new variable is both numerical and only encodes one meaning (contact duration) which satisfies our two criteria above. Given that -1 means either we don't know the outcome or we know the customer never resonded, then using the median duration period assumes that these customers are likely similar enough to the average customer who did respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "57bb73b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.0\n",
      "11157    182\n",
      "11158    182\n",
      "11159    182\n",
      "11160    172\n",
      "11161    182\n",
      "Name: pdays_duration, dtype: int64\n",
      "       age  balance  day  duration  campaign  pdays  previous deposit  \\\n",
      "11157   33        1   20       257         1     -1         0      no   \n",
      "11158   39      733   16        83         4     -1         0      no   \n",
      "11159   32       29   19       156         2     -1         0      no   \n",
      "11160   43        0    8         9         2    172         5      no   \n",
      "11161   34        0    9       628         1     -1         0      no   \n",
      "\n",
      "       job_admin.  job_blue-collar  ...  month_may  month_nov  month_oct  \\\n",
      "11157           0                1  ...          0          0          0   \n",
      "11158           0                0  ...          0          0          0   \n",
      "11159           0                0  ...          0          0          0   \n",
      "11160           0                0  ...          1          0          0   \n",
      "11161           0                0  ...          0          0          0   \n",
      "\n",
      "       month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "11157          0                 0               0                 0   \n",
      "11158          0                 0               0                 0   \n",
      "11159          0                 0               0                 0   \n",
      "11160          0                 1               0                 0   \n",
      "11161          0                 0               0                 0   \n",
      "\n",
      "       poutcome_unknown  prev_contacted  pdays_duration  \n",
      "11157                 1               0             182  \n",
      "11158                 1               0             182  \n",
      "11159                 1               0             182  \n",
      "11160                 0               1             172  \n",
      "11161                 1               0             182  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# We create a new binary column with value = 1 if previously contacted and 0 if pdays = -1 (no previous contact)\n",
    "df_encoded[\"prev_contacted\"] = (df_encoded[\"pdays\"] != -1).astype(int)\n",
    "# We only calculate the median on values greater than -1\n",
    "known_pdays = df_encoded.loc[df_encoded['pdays'] != -1, \"pdays\"]\n",
    "median_pdays = known_pdays.median()\n",
    "print(median_pdays)\n",
    "\n",
    "# We replace all -1 values with the median of the know_pdays\n",
    "df_encoded['pdays_duration'] = df_encoded['pdays'].replace(-1, median_pdays)\n",
    "print(df_encoded['pdays_duration'].tail())\n",
    "print(df_encoded.tail())\n",
    "\n",
    "# We drop the original pdays variable\n",
    "df_encoded.drop('pdays', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc421383",
   "metadata": {},
   "source": [
    "After we have all of our training variables cleaned and in the format we want them in, we finally convert our target variable *deposit* to a binary integer value. Then, to prepare our data for training and test validation using the holdout method, we divide our data into \"attributes\" and \"class\" sets, and then divide those sets into \"test\" and \"training\".\n",
    "\n",
    "In order to scale our numerical/continuous columns (excluding the categorical columns created with one-hot encoding), we use a transformer to discriminate and scale the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c8104d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We convert yes to 1 and no to 0 for the target 'deposit'\n",
    "df_encoded[\"deposit\"] = df_encoded[\"deposit\"].map({\"yes\": 1, \"no\": 0}) #Used AI to convert yes to 1 and no to 0 in the target column 'deposit'\n",
    "\n",
    "y = df_encoded[\"deposit\"]\n",
    "X = df_encoded.drop(\"deposit\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE_ID)\n",
    "\n",
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'previous', 'pdays_duration']\n",
    "cat_cols = [col for col in df_encoded.columns if col not in num_cols and col != 'deposit']  # Used AI to create the loop selecting all columns that are not in num_cols and are not 'deposit'\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols), \n",
    "        ('cat', 'passthrough', cat_cols) \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bf0b8",
   "metadata": {},
   "source": [
    "We also want to consider if our data is imbalanced or not. From the graph below, we can see that the distribution of the classes for our target variable are relatively evenly distributed. When we calculate the proportion of each class, we can see that the 0 class only makes up about 53% of the total distribution, meaning that we should aim for our model to have an accuracy greater than 52%. This is to say that our dataset is not imbalanced as long as we don't have a model that performs incredibly poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7300ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52545\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(round(y.value_counts()[0]/y.count(), 5))\n",
    "\n",
    "pd.Series(y).value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31654c",
   "metadata": {},
   "source": [
    "\n",
    "Our test partition is 20% of the overall dataset. A rule of thumb when deciding the test size for the holdout method is that as the size of the dataset increases, the size of the test partition is able to become smaller while still maintaining the same margin of error for measuring the estimated accuracy. With the below calculated margins of error [insert Edouard magic here], we can see that with our dataset size (11,000 observations), we should still expect a reasonable margin of error when validating the performance of the model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d2168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in test: 2200 \n",
      "Observations in train: 8800\n"
     ]
    }
   ],
   "source": [
    "# [Insert Edouard magic here]\n",
    "num_test = y_test.count()\n",
    "print(f\"Observations in test: {num_test}\",\n",
    "      f\"\\nObservations in train: {11000 - num_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4ee72",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75348c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "start_time = time.time()\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "training_times[\"lr\"] = time.time() - start_time\n",
    "\n",
    "y_pred_log = logreg.predict(X_test_processed)\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(accuracy_log)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51bda515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8020646663080251 0.8342989700556114\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_log = np.sqrt((accuracy_log*(1-accuracy_log))/n) \n",
    "\n",
    "ci_upper = accuracy_log + se_log*z\n",
    "ci_lower = accuracy_log - se_log*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14a571",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7995454545454546\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(X_train_processed, y_train)\n",
    "training_times[\"knn\"] = time.time() - start_time\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_processed)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2c4d0800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828162895473836 0.8162746195435255\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_knn = np.sqrt((accuracy_knn*(1-accuracy_knn))/n) \n",
    "\n",
    "ci_upper = accuracy_knn + se_knn*z\n",
    "ci_lower = accuracy_knn - se_knn*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ac996",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Tree** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777272727272727\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "tree = tree.fit(X_train_processed, y_train)\n",
    "training_times[\"tree\"] = time.time() - start_time\n",
    "\n",
    "y_pred_tree = tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a244f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7603532060274768 0.7951013394270686\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_tree = np.sqrt((accuracy_tree*(1-accuracy_tree))/n) \n",
    "\n",
    "ci_upper = accuracy_tree + se_tree*z\n",
    "ci_lower = accuracy_tree - se_tree*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16d379",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Dummy Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c713666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519090909090909\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0942093",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efa349",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec4dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'C': np.float64(4.281332398719396), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score (Random Search): 0.8185949201235179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid_lr = {\n",
    "    'C' : np.logspace(-4, 4, 20), \n",
    "    'penalty': ['l2'],             \n",
    "    'solver': ['lbfgs', 'liblinear'] \n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=RANDOM_STATE_ID, max_iter=1000)\n",
    "\n",
    "# Find best hyperparameters using RandomizedSearchCV\n",
    "grid_search = GridSearchCV(logistic, param_grid=param_grid_lr, \n",
    "                                     cv=5,\n",
    "                                   scoring='f1',\n",
    "                                    n_jobs=1\n",
    ")\n",
    "\n",
    "# Train the model with best hyperparameters\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "tuning_times[\"lr\"] = time.time() - start_time\n",
    "best_params= grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e18705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8154545454545454\n",
      "{'lr': 8.165611743927002}\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy over entire training set\n",
    "tuned_lr = grid_search.best_estimator_\n",
    "y_pred_tuned = tuned_lr.predict(X_test_processed)\n",
    "accuracy_tuned_lr = accuracy_score(y_pred_tuned,y_test )\n",
    "\n",
    "print(accuracy_tuned_lr)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "218cb422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992440500925958 0.8316650408164951\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_log_tuned = np.sqrt((accuracy_tuned_lr*(1-accuracy_tuned_lr))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_lr + se_log_tuned*z\n",
    "ci_lower = accuracy_tuned_lr - se_log_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5f712",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e042932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best Score (Random Search): 0.8103409090909091\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "grid_search_knn = GridSearchCV(knn, param_grid=param_grid_knn, \n",
    "                                cv=5, scoring=\"accuracy\", \n",
    "                                n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_knn.fit(X_train_processed, y_train)\n",
    "tuning_times[\"knn\"] = time.time() - start_time\n",
    "best_params= grid_search_knn.best_params_\n",
    "best_score = grid_search_knn.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163636363636364\n",
      "{'lr': 8.165611743927002, 'knn': 10.731130123138428}\n"
     ]
    }
   ],
   "source": [
    "tuned_knn = grid_search_knn.best_estimator_\n",
    "y_pred_tuned = tuned_knn.predict(X_test_processed)\n",
    "accuracy_tuned_knn = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tuned_knn)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7bb28e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001531410016868 0.832574131725586\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_knn_tuned = np.sqrt((accuracy_tuned_knn*(1-accuracy_tuned_knn))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_knn + se_knn_tuned*z\n",
    "ci_lower = accuracy_tuned_knn - se_knn_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bf047",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f993f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'criterion': 'gini', 'max_depth': 13, 'min_samples_leaf': 18, 'min_samples_split': 3}\n",
      "Best Score (Random Search): 0.8294310648952874\n"
     ]
    }
   ],
   "source": [
    "param_dist_tree = {\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20)\n",
    "}\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "random_search_tree = RandomizedSearchCV(tree, param_distributions=param_dist_tree, \n",
    "                                   cv=3, scoring='accuracy',\n",
    "                                   n_iter=50, random_state=RANDOM_STATE_ID,\n",
    "                                   n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search_tree.fit(X_train_processed, y_train)\n",
    "tuning_times[\"tree\"] = time.time() - start_time\n",
    "best_params= random_search_tree.best_params_\n",
    "best_score = random_search_tree.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb835659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8368181818181818\n",
      "{'lr': 8.165611743927002, 'knn': 10.731130123138428, 'tree': 3.6735360622406006}\n"
     ]
    }
   ],
   "source": [
    "tuned_tree = random_search_tree.best_estimator_\n",
    "y_pred_tuned = tuned_tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree_tuned = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tree_tuned)\n",
    "print(tuning_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9590ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8213764442036524 0.8522599194327112\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_tree_tuned = np.sqrt((accuracy_tree_tuned*(1-accuracy_tree_tuned))/n) \n",
    "\n",
    "ci_upper = accuracy_tree_tuned + se_tree_tuned*z\n",
    "ci_lower = accuracy_tree_tuned - se_tree_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb47214",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Dummy Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "801f06c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519090909090909\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4ace0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **Advanced Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b41ab",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 0.8563636363636363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_model.fit(X_train_processed, y_train)\n",
    "training_times[\"svm_model\"] = time.time() - start_time\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_pred_svm, y_test)\n",
    "\n",
    "print(\"SVM Accuracy Score:\", accuracy_svm)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "897eb3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417079541076244 0.8710193186196482\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_svm = np.sqrt((accuracy_svm*(1-accuracy_svm))/n) \n",
    "\n",
    "ci_upper = accuracy_svm + se_svm*z\n",
    "ci_lower = accuracy_svm- se_svm*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score is 0.85375\n"
     ]
    }
   ],
   "source": [
    "#Tuned SVM\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['rbf']} \n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit = True, n_jobs=-1) \n",
    "\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(f'Best parameter is {grid_search.best_params_}')\n",
    "print(f'Best score is {grid_search.best_score_}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM Accuracy score: 0.8582\n"
     ]
    }
   ],
   "source": [
    "tuned_svm = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tuned_svm = tuned_svm.predict(X_test_processed)\n",
    "\n",
    "accuracy_tuned_svm = accuracy_score(y_pred_tuned_svm, y_test)\n",
    "\n",
    "print(f\"Tuned SVM Accuracy score: {accuracy_tuned_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "86eb38cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436037377474463 0.87275989861619\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_svm_tuned = np.sqrt((accuracy_tuned_svm*(1-accuracy_tuned_svm))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_svm + se_svm_tuned*z\n",
    "ci_lower = accuracy_tuned_svm- se_svm_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e245b",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **Random Forest Classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy score: 0.8522727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE_ID)\n",
    "start_time = time.time()\n",
    "\n",
    "rf.fit(X_train_processed, y_train)\n",
    "training_times[\"rf\"] = time.time() - start_time\n",
    "\n",
    "y_pred_rf= rf.predict(X_test_processed)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
    "\n",
    "print(\"Random Forest Accuracy score:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "42daf178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374453490231826 0.867100105522272\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_rf = np.sqrt((accuracy_rf*(1-accuracy_rf))/n) \n",
    "\n",
    "ci_upper = accuracy_rf + se_rf*z\n",
    "ci_lower = accuracy_rf- se_rf*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679d88a",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a236e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score: 0.8563636363636363\n",
      "{'lr': 0.06198596954345703, 'knn': 0.0045130252838134766, 'tree': 0.092742919921875, 'svm_model': 1.0750370025634766, 'rf': 0.756624698638916, 'xgb_model': 0.1907200813293457}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    objective='binary:logistic', \n",
    "    random_state=RANDOM_STATE_ID\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "training_times[\"xgb_model\"] = time.time() - start_time\n",
    "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_pred_xgb, y_test)\n",
    "\n",
    "print(\"XGBoost accuracy score:\", accuracy_xgb)\n",
    "print(training_times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0872e79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417079541076244 0.8710193186196482\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_xgb = np.sqrt((accuracy_xgb*(1-accuracy_xgb))/n) \n",
    "\n",
    "ci_upper = accuracy_xgb + se_xgb*z\n",
    "ci_lower = accuracy_xgb- se_xgb*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 7, 'subsample': 0.7}\n",
      "Best score:  0.8635227272727273\n"
     ]
    }
   ],
   "source": [
    "#Tuned XGboost \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tuned XGB:, 0.8600\n"
     ]
    }
   ],
   "source": [
    "tuned_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tuned_xgb = tuned_xgb.predict(X_test_processed)\n",
    "\n",
    "accuracy_tuned_xgb = accuracy_score(y_pred_tuned_xgb, y_test)\n",
    "\n",
    "print(f\"Accuracy Tuned XGB:, {accuracy_tuned_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34cbb8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8455003348001034 0.8744996651998965\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_xgb_tuned = np.sqrt((accuracy_tuned_xgb*(1-accuracy_tuned_xgb))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_xgb + se_xgb_tuned*z\n",
    "ci_lower = accuracy_tuned_xgb - se_xgb_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4f432",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model                  Accuracy without hyperparameter tuning (%)    Accuracy after hyperparameters tuning (%)    Accuracy improvement (%)    Training time (s)    Hyperparameter tuning time (s)\n",
      "-------------------  --------------------------------------------  -------------------------------------------  --------------------------  -------------------  --------------------------------\n",
      "Logistic Regression                                        0.8182                                       0.8155                     -0.0033               0.062                             8.1656\n",
      "KNN                                                        0.7995                                       0.8164                      0.021                0.0045                           10.7311\n",
      "Decision Tree                                              0.7777                                       0.8368                      0.076                0.0927                            3.6735\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate\n",
    "import tabulate\n",
    "\n",
    "## Results to report (in a table):\n",
    "\n",
    "# by model (KNN, LR, DT)\n",
    "models = ['Logistic Regression', 'KNN', 'Decision Tree']\n",
    "\n",
    "# confidence intervals (RMSE)\n",
    "#  before hyperparameter tuning\n",
    "accuracies = [accuracy_log, accuracy_knn, accuracy_tree]\n",
    "#  after hyperparameter tuning\n",
    "tuned_accuracies = [accuracy_tuned_lr, accuracy_tuned_knn, accuracy_tree_tuned]\n",
    "# accuracy improvement\n",
    "accuracy_improvement = [(tuned_accuracies[idx] - acc) / acc for idx, acc in enumerate(accuracies)]\n",
    "\n",
    "# training time\n",
    "training_times\n",
    "# hyperparam tuning time\n",
    "tuning_times\n",
    "\n",
    "\n",
    "headings = [\n",
    "    'Model',\n",
    "    'Accuracy without hyperparameter tuning (%)',\n",
    "    'Accuracy after hyperparameters tuning (%)',\n",
    "    'Accuracy improvement (%)',\n",
    "    'Training time (s)',\n",
    "    'Hyperparameter tuning time (s)',\n",
    "]\n",
    "\n",
    "data = [\n",
    "    models,\n",
    "    accuracies,\n",
    "    tuned_accuracies,\n",
    "    accuracy_improvement,\n",
    "    [training_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "    [tuning_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "]\n",
    "\n",
    "# round all numbered data\n",
    "data = [[round(e, 4) for e in col] if type(col[0]) is not str else col for col in data]\n",
    "\n",
    "data = np.array(data).transpose()\n",
    "\n",
    "print(tabulate.tabulate(data, headers=headings))\n",
    "\n",
    "# draw conclusions about different models (which ones benefited the most from hyper-tuning, speed, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c95066",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **Results**\n",
    "\n",
    "| Model | Accuracy - no hyperparameter tuning |95 % Confidence Interval| Accuracy - tuned hyperparameters |95% Confidence Interval| Accuracy Improvement (%)| Training time (s) | Hyperparameter tuning time (s)|\n",
    "|-------|--------|---------|----------|-----------|------------|--------|-------|\n",
    "|Logistic Regression|0.8182|[0.802, 0.834]|0.8155|[0.799, 0.8317]|-3.3|0.0529|5.3054|\n",
    "|KNN|0.7995|[0.783, 0.816]|0.8164|[0.800, 0.8326]|2.1|0.0039|16.8341|\n",
    "|Decision Tree|0.785|[0.7604, 0.7951]|0.8368|[0.8214, 0.8523]|6.6|0.0802|4.9904|\n",
    "|SVM|0.8564|[0.8417, 0.871]|0.8582|[0.8436, 0.873]|0.21|1.257|84|\n",
    "|Random Forest|0.8522|[0.837, 0.867]|/|/|/|1.02|/|\n",
    "|XGboost|0.8564|[0.8417, 0.871]|0.86|[0.8455, 0.8745]|0.42|0.268|21|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f272ab3",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 1000px; font-family: 'Georgia', serif; font-size: 14px; line-height: 1.6;\">\n",
    "\n",
    "\n",
    "## **Comments**\n",
    "\n",
    "### <u>**Base Models**</u>\n",
    "From the above table, we note that out off the base models, the logistic regression performed the best with an accuracy score of 81.8 %. Then came the KNN method and finally the Decision Tree with accuracies of 79.95% and 78.5% respectively. \n",
    "\n",
    "\n",
    "\n",
    "#### **After hyperparameter tuning** \n",
    "After hyperparameter tuning, the Decision Tree method achieved both the overall highest accuracy of all base models with 83.68% \n",
    "and the greatest improvement in accuracy (6.6%). A surprising result comes from the Logistic Regression, who displayed a decrease of 3.3% in accuracy after tuning the hyperparameters.\n",
    "\n",
    "\n",
    "#### **Tuning time** \n",
    "Overall, it is also the Decision Tree model that displayed the lowest hyperparameter tuning time with 4.99 seconds compared to 5.3 seconds \n",
    "for the Logistic Regression and a much higher value of 16.8 seconds for KNN.\n",
    "\n",
    "### <u>**Advanced Models**</u>\n",
    "\n",
    "All three of the  (untuned) advanced models performed better than the base models before and after hyperparameter tuning. They all present similar accuracy scores with SVM and XGboost achieving a slightly higher (and identical) accuracy of 85.64 %. \n",
    "\n",
    "We checked the confusion matrix for XGboost and SVM and noticed that they had different numbers of correct predictions for class 0 and class 1 (has the client subscribed a term deposit?) but overall achieved the same number of total correct predictions, which explains one they achieved identical accuracy scores.\n",
    "\n",
    "#### **After hyperparameter tuning**\n",
    "\n",
    "We decide to tuned the SVM and XGBoost models as they presented the highest accuracy of the advanced models. XGBoost achieved the higher accuracy score increase of the 2 (0.42%), with a final accuracy of 86%. It also had the faster hyperparameter tuning time with 21 seconds compared to 84 seconds for SVM (only improving accuracy by 0.21%)\n",
    "\n",
    "### <u>**Conclusion**</u>\n",
    "\n",
    "We conclude that we should use the more advanced prediction models for this problem as they all presented higher accuracy scores than the base models. We would favour the XGboost model as it presented the highest overall accuracy of all models (tuned and untuned) and as tuning was faster for that specifc model. \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f113c",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "## **Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Load test dataset\n",
    "\n",
    "test_set = pd.read_pickle(COMPETITION_DATA_PATH)\n",
    "\n",
    "print(test_set.columns)\n",
    "\n",
    "# make predictions about this using the best method\n",
    "\n",
    "# save final model (in notes)\n",
    "# save predictions in a file (pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
