{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b926ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zavier Morales\n",
    "# Edouard Mason\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define global variables & import data\n",
    "\n",
    "RANDOM_STATE_ID = 100577770\n",
    "\n",
    "TRAINING_DATA_PATH = Path('dataset', 'bank_06.pkl')\n",
    "COMPETITION_DATA_PATH = Path('dataset', 'bank_competition.pkl')\n",
    "\n",
    "training_times = {}\n",
    "tuning_times = {}\n",
    "prediction_times = {}\n",
    "\n",
    "raw_data = pd.read_pickle(TRAINING_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcefc7",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c6ca3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      " (11000, 17)\n",
      "\n",
      "First few rows:\n",
      "    age         job  marital  education default  balance housing loan  contact  \\\n",
      "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
      "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
      "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
      "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
      "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
      "\n",
      "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
      "0    5   may      1042         1     -1         0  unknown     yes  \n",
      "1    5   may      1467         1     -1         0  unknown     yes  \n",
      "2    5   may      1389         1     -1         0  unknown     yes  \n",
      "3    5   may       579         1     -1         0  unknown     yes  \n",
      "4    5   may       673         2     -1         0  unknown     yes  \n",
      "\n",
      "List of columns:\n",
      " Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'deposit'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Target variable: 0    yes\n",
      "1    yes\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "Name: deposit, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset:\\n\", raw_data.shape)\n",
    "print(\"\\nFirst few rows:\\n\",raw_data.head())\n",
    "print(\"\\nList of columns:\\n\",raw_data.columns)\n",
    "print(\"\\n\\n\\nTarget variable:\",raw_data['deposit'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1188cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            76\n",
      "job            12\n",
      "marital         3\n",
      "education       4\n",
      "default         2\n",
      "balance      3783\n",
      "housing         2\n",
      "loan            2\n",
      "contact         3\n",
      "day            31\n",
      "month          12\n",
      "duration     1423\n",
      "campaign       36\n",
      "pdays         472\n",
      "previous       34\n",
      "poutcome        4\n",
      "deposit         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Cardinality of variables\n",
    "unique_counts = raw_data.nunique()\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "012a3f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the DataFrame:\n",
      "\n",
      " Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'deposit', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
      "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
      "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
      "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
      "       'education_primary', 'education_secondary', 'education_tertiary',\n",
      "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
      "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
      "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
      "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
      "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
      "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
      "       'poutcome_unknown'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "\n",
      "    age  balance  day  duration  campaign  pdays  previous deposit  job_admin.  \\\n",
      "0   59     2343    5      1042         1     -1         0     yes           1   \n",
      "1   56       45    5      1467         1     -1         0     yes           1   \n",
      "2   41     1270    5      1389         1     -1         0     yes           0   \n",
      "3   55     2476    5       579         1     -1         0     yes           0   \n",
      "4   54      184    5       673         2     -1         0     yes           1   \n",
      "\n",
      "   job_blue-collar  ...  month_jun  month_mar  month_may  month_nov  \\\n",
      "0                0  ...          0          0          1          0   \n",
      "1                0  ...          0          0          1          0   \n",
      "2                0  ...          0          0          1          0   \n",
      "3                0  ...          0          0          1          0   \n",
      "4                0  ...          0          0          1          0   \n",
      "\n",
      "   month_oct  month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "0          0          0                 0               0                 0   \n",
      "1          0          0                 0               0                 0   \n",
      "2          0          0                 0               0                 0   \n",
      "3          0          0                 0               0                 0   \n",
      "4          0          0                 0               0                 0   \n",
      "\n",
      "   poutcome_unknown  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "\n",
      "Missing values per column:\n",
      "\n",
      " age                    0\n",
      "balance                0\n",
      "day                    0\n",
      "duration               0\n",
      "campaign               0\n",
      "pdays                  0\n",
      "previous               0\n",
      "deposit                0\n",
      "job_admin.             0\n",
      "job_blue-collar        0\n",
      "job_entrepreneur       0\n",
      "job_housemaid          0\n",
      "job_management         0\n",
      "job_retired            0\n",
      "job_self-employed      0\n",
      "job_services           0\n",
      "job_student            0\n",
      "job_technician         0\n",
      "job_unemployed         0\n",
      "job_unknown            0\n",
      "marital_divorced       0\n",
      "marital_married        0\n",
      "marital_single         0\n",
      "education_primary      0\n",
      "education_secondary    0\n",
      "education_tertiary     0\n",
      "education_unknown      0\n",
      "default_no             0\n",
      "default_yes            0\n",
      "housing_no             0\n",
      "housing_yes            0\n",
      "loan_no                0\n",
      "loan_yes               0\n",
      "contact_cellular       0\n",
      "contact_telephone      0\n",
      "contact_unknown        0\n",
      "month_apr              0\n",
      "month_aug              0\n",
      "month_dec              0\n",
      "month_feb              0\n",
      "month_jan              0\n",
      "month_jul              0\n",
      "month_jun              0\n",
      "month_mar              0\n",
      "month_may              0\n",
      "month_nov              0\n",
      "month_oct              0\n",
      "month_sep              0\n",
      "poutcome_failure       0\n",
      "poutcome_other         0\n",
      "poutcome_success       0\n",
      "poutcome_unknown       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoding object-type variables\n",
    "df_encoded = pd.get_dummies(raw_data, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'])\n",
    "\n",
    "#Converting all boolean columns to integers (1 for True, 0 for False)\n",
    "df_encoded[df_encoded.select_dtypes(include=['bool']).columns] = df_encoded.select_dtypes(include=['bool']).astype(int)\n",
    "print(\"\\nColumns in the DataFrame:\\n\\n\",df_encoded.columns)\n",
    "print(\"\\n\\nFirst few rows of the DataFrame:\\n\\n\",df_encoded.head())\n",
    "\n",
    "#Checking the number of missing values per column\n",
    "missing_values = df_encoded.isnull().sum()\n",
    "print(\"\\nMissing values per column:\\n\\n\", missing_values)   #We get 0 for each column so we have no missing values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e326819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8203\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where pdays == -1\n",
    "count_minus1 = (raw_data['pdays'] == -1).sum()\n",
    "\n",
    "print(count_minus1)\n",
    "\n",
    "# We see that there are 8203 where pdays = -1, that is where we have no info or contact. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57bb73b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.0\n"
     ]
    }
   ],
   "source": [
    "# We create a new binary column with value = 1 if previously contacted and 0 if pdays = -1 (no previous contact)\n",
    "df_encoded[\"prev_contacted\"] = (df_encoded[\"pdays\"] != -1).astype(int)\n",
    "# We only calculate the median on values greater than -1\n",
    "known_pdays = df_encoded.loc[df_encoded['pdays'] != -1, \"pdays\"]\n",
    "median_pdays = known_pdays.median()\n",
    "print(median_pdays)\n",
    "\n",
    "# We replace all -1 values with the median of the know_pdays\n",
    "df_encoded['pdays_duration'] = df_encoded['pdays'].replace(-1, median_pdays)\n",
    "\n",
    "# We drop the original pdays variable\n",
    "df_encoded.drop('pdays', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a5e5fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11157    182\n",
      "11158    182\n",
      "11159    182\n",
      "11160    172\n",
      "11161    182\n",
      "Name: pdays_duration, dtype: int64\n",
      "       age  balance  day  duration  campaign  previous deposit  job_admin.  \\\n",
      "11157   33        1   20       257         1         0      no           0   \n",
      "11158   39      733   16        83         4         0      no           0   \n",
      "11159   32       29   19       156         2         0      no           0   \n",
      "11160   43        0    8         9         2         5      no           0   \n",
      "11161   34        0    9       628         1         0      no           0   \n",
      "\n",
      "       job_blue-collar  job_entrepreneur  ...  month_may  month_nov  \\\n",
      "11157                1                 0  ...          0          0   \n",
      "11158                0                 0  ...          0          0   \n",
      "11159                0                 0  ...          0          0   \n",
      "11160                0                 0  ...          1          0   \n",
      "11161                0                 0  ...          0          0   \n",
      "\n",
      "       month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
      "11157          0          0                 0               0   \n",
      "11158          0          0                 0               0   \n",
      "11159          0          0                 0               0   \n",
      "11160          0          0                 1               0   \n",
      "11161          0          0                 0               0   \n",
      "\n",
      "       poutcome_success  poutcome_unknown  prev_contacted  pdays_duration  \n",
      "11157                 0                 1               0             182  \n",
      "11158                 0                 1               0             182  \n",
      "11159                 0                 1               0             182  \n",
      "11160                 0                 0               1             172  \n",
      "11161                 0                 1               0             182  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded['pdays_duration'].tail())\n",
    "print(df_encoded.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5a665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "deposit      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8104d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We convert yes to 1 and no to 0 for the target 'deposit'\n",
    "df_encoded[\"deposit\"] = df_encoded[\"deposit\"].map({\"yes\": 1, \"no\": 0}) #Used AI to convert yes to 1 and no to 0 in the target column 'deposit'\n",
    "\n",
    "y = df_encoded[\"deposit\"]\n",
    "X = df_encoded.drop(\"deposit\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE_ID)\n",
    "\n",
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'previous', 'pdays_duration']\n",
    "cat_cols = [col for col in df_encoded.columns if col not in num_cols and col != 'deposit']  # Used AI to create the loop selecting all columns that are not in num_cols and are not 'deposit'\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols), \n",
    "        ('cat', 'passthrough', cat_cols) \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4ee72",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75348c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "start_time = time.time()\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "training_times[\"lr\"] = time.time() - start_time\n",
    "\n",
    "y_pred_log = logreg.predict(X_test_processed)\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(accuracy_log)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51bda515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8020646663080251 0.8342989700556114\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_log = np.sqrt((accuracy_log*(1-accuracy_log))/n) \n",
    "\n",
    "ci_upper = accuracy_log + se_log*z\n",
    "ci_lower = accuracy_log - se_log*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14a571",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7995454545454546\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(X_train_processed, y_train)\n",
    "training_times[\"knn\"] = time.time() - start_time\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_processed)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2c4d0800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828162895473836 0.8162746195435255\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_knn = np.sqrt((accuracy_knn*(1-accuracy_knn))/n) \n",
    "\n",
    "ci_upper = accuracy_knn + se_knn*z\n",
    "ci_lower = accuracy_knn - se_knn*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ac996",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Tree** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777272727272727\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "tree = tree.fit(X_train_processed, y_train)\n",
    "training_times[\"tree\"] = time.time() - start_time\n",
    "\n",
    "y_pred_tree = tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a244f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7603532060274768 0.7951013394270686\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_tree = np.sqrt((accuracy_tree*(1-accuracy_tree))/n) \n",
    "\n",
    "ci_upper = accuracy_tree + se_tree*z\n",
    "ci_lower = accuracy_tree - se_tree*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0942093",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efa349",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec4dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'C': np.float64(4.281332398719396), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score (Random Search): 0.8185949201235179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid_lr = {\n",
    "    'C' : np.logspace(-4, 4, 20), \n",
    "    'penalty': ['l2'],             \n",
    "    'solver': ['lbfgs', 'liblinear'] \n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=RANDOM_STATE_ID, max_iter=1000)\n",
    "\n",
    "# Find best hyperparameters using RandomizedSearchCV\n",
    "grid_search = GridSearchCV(logistic, param_grid=param_grid_lr, \n",
    "                                     cv=5,\n",
    "                                   scoring='f1',\n",
    "                                    n_jobs=1\n",
    ")\n",
    "\n",
    "# Train the model with best hyperparameters\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "tuning_times[\"lr\"] = time.time() - start_time\n",
    "best_params= grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e18705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8154545454545454\n",
      "{'lr': 8.165611743927002}\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy over entire training set\n",
    "tuned_lr = grid_search.best_estimator_\n",
    "y_pred_tuned = tuned_lr.predict(X_test_processed)\n",
    "accuracy_tuned_lr = accuracy_score(y_pred_tuned,y_test )\n",
    "\n",
    "print(accuracy_tuned_lr)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "218cb422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992440500925958 0.8316650408164951\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_log_tuned = np.sqrt((accuracy_tuned_lr*(1-accuracy_tuned_lr))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_lr + se_log_tuned*z\n",
    "ci_lower = accuracy_tuned_lr - se_log_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5f712",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "\n",
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e042932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best Score (Random Search): 0.8103409090909091\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "grid_search_knn = GridSearchCV(knn, param_grid=param_grid_knn, \n",
    "                                cv=5, scoring=\"accuracy\", \n",
    "                                n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_knn.fit(X_train_processed, y_train)\n",
    "tuning_times[\"knn\"] = time.time() - start_time\n",
    "best_params= grid_search_knn.best_params_\n",
    "best_score = grid_search_knn.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163636363636364\n",
      "{'lr': 8.165611743927002, 'knn': 10.731130123138428}\n"
     ]
    }
   ],
   "source": [
    "tuned_knn = grid_search_knn.best_estimator_\n",
    "y_pred_tuned = tuned_knn.predict(X_test_processed)\n",
    "accuracy_tuned_knn = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tuned_knn)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb28e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001531410016868 0.832574131725586\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_knn_tuned = np.sqrt((accuracy_tuned_knn*(1-accuracy_tuned_knn))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_knn + se_knn_tuned*z\n",
    "ci_lower = accuracy_tuned_knn - se_knn_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bf047",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "### **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f993f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'criterion': 'gini', 'max_depth': 13, 'min_samples_leaf': 18, 'min_samples_split': 3}\n",
      "Best Score (Random Search): 0.8294310648952874\n"
     ]
    }
   ],
   "source": [
    "param_dist_tree = {\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20)\n",
    "}\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "random_search_tree = RandomizedSearchCV(tree, param_distributions=param_dist_tree, \n",
    "                                   cv=3, scoring='accuracy',\n",
    "                                   n_iter=50, random_state=RANDOM_STATE_ID,\n",
    "                                   n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search_tree.fit(X_train_processed, y_train)\n",
    "tuning_times[\"tree\"] = time.time() - start_time\n",
    "best_params= random_search_tree.best_params_\n",
    "best_score = random_search_tree.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb835659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8368181818181818\n",
      "{'lr': 8.165611743927002, 'knn': 10.731130123138428, 'tree': 3.6735360622406006}\n"
     ]
    }
   ],
   "source": [
    "tuned_tree = random_search_tree.best_estimator_\n",
    "y_pred_tuned = tuned_tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree_tuned = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tree_tuned)\n",
    "print(tuning_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9590ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8213764442036524 0.8522599194327112\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_tree_tuned = np.sqrt((accuracy_tree_tuned*(1-accuracy_tree_tuned))/n) \n",
    "\n",
    "ci_upper = accuracy_tree_tuned + se_tree_tuned*z\n",
    "ci_lower = accuracy_tree_tuned - se_tree_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4ace0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **Advanced Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b41ab",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 0.8563636363636363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_model.fit(X_train_processed, y_train)\n",
    "training_times[\"svm_model\"] = time.time() - start_time\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_pred_svm, y_test)\n",
    "\n",
    "print(\"SVM Accuracy Score:\", accuracy_svm)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best score is 0.85375\n"
     ]
    }
   ],
   "source": [
    "#Tuned SVM\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['rbf']} \n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit = True, n_jobs=-1) \n",
    "\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(f'Best parameter is {grid_search.best_params_}')\n",
    "print(f'Best score is {grid_search.best_score_}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM Accuracy score: 0.8582\n"
     ]
    }
   ],
   "source": [
    "tuned_svm = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tuned_svm = tuned_svm.predict(X_test_processed)\n",
    "\n",
    "accuracy_tuned_svm = accuracy_score(y_pred_tuned_svm, y_test)\n",
    "\n",
    "print(f\"Tuned SVM Accuracy score: {accuracy_tuned_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "86eb38cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436037377474463 0.87275989861619\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_svm_tuned = np.sqrt((accuracy_tuned_svm*(1-accuracy_tuned_svm))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_svm + se_svm_tuned*z\n",
    "ci_lower = accuracy_tuned_svm- se_svm_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e245b",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **Random Forest Classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy score: 0.8522727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE_ID)\n",
    "start_time = time.time()\n",
    "\n",
    "rf.fit(X_train_processed, y_train)\n",
    "training_times[\"rf\"] = time.time() - start_time\n",
    "\n",
    "y_pred_rf= rf.predict(X_test_processed)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
    "\n",
    "print(\"Random Forest Accuracy score:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679d88a",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a236e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score: 0.8563636363636363\n",
      "{'lr': 0.06198596954345703, 'knn': 0.0045130252838134766, 'tree': 0.092742919921875, 'svm_model': 1.0750370025634766, 'rf': 0.756624698638916, 'xgb_model': 0.1907200813293457}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    objective='binary:logistic', \n",
    "    random_state=RANDOM_STATE_ID\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "training_times[\"xgb_model\"] = time.time() - start_time\n",
    "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_pred_xgb, y_test)\n",
    "\n",
    "print(\"XGBoost accuracy score:\", accuracy_xgb)\n",
    "print(training_times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 7, 'subsample': 0.7}\n",
      "Best score:  0.8635227272727273\n"
     ]
    }
   ],
   "source": [
    "#Tuned XGboost \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tuned XGB:, 0.8600\n"
     ]
    }
   ],
   "source": [
    "tuned_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tuned_xgb = tuned_xgb.predict(X_test_processed)\n",
    "\n",
    "accuracy_tuned_xgb = accuracy_score(y_pred_tuned_xgb, y_test)\n",
    "\n",
    "print(f\"Accuracy Tuned XGB:, {accuracy_tuned_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34cbb8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8455003348001034 0.8744996651998965\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval\n",
    "\n",
    "n = len(y_test)\n",
    "z = 1.96\n",
    "\n",
    "se_xgb_tuned = np.sqrt((accuracy_tuned_xgb*(1-accuracy_tuned_xgb))/n) \n",
    "\n",
    "ci_upper = accuracy_tuned_xgb + se_xgb_tuned*z\n",
    "ci_lower = accuracy_tuned_xgb - se_xgb_tuned*z\n",
    "\n",
    "print(ci_lower, ci_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4f432",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model                  Accuracy without hyperparameter tuning (%)    Accuracy after hyperparameters tuning (%)    Accuracy improvement (%)    Training time (s)    Hyperparameter tuning time (s)\n",
      "-------------------  --------------------------------------------  -------------------------------------------  --------------------------  -------------------  --------------------------------\n",
      "Logistic Regression                                        0.8182                                       0.8155                     -0.0033               0.062                             8.1656\n",
      "KNN                                                        0.7995                                       0.8164                      0.021                0.0045                           10.7311\n",
      "Decision Tree                                              0.7777                                       0.8368                      0.076                0.0927                            3.6735\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate\n",
    "import tabulate\n",
    "\n",
    "## Results to report (in a table):\n",
    "\n",
    "# by model (KNN, LR, DT)\n",
    "models = ['Logistic Regression', 'KNN', 'Decision Tree']\n",
    "\n",
    "# confidence intervals (RMSE)\n",
    "#  before hyperparameter tuning\n",
    "accuracies = [accuracy_log, accuracy_knn, accuracy_tree]\n",
    "#  after hyperparameter tuning\n",
    "tuned_accuracies = [accuracy_tuned_lr, accuracy_tuned_knn, accuracy_tree_tuned]\n",
    "# accuracy improvement\n",
    "accuracy_improvement = [(tuned_accuracies[idx] - acc) / acc for idx, acc in enumerate(accuracies)]\n",
    "\n",
    "# training time\n",
    "training_times\n",
    "# hyperparam tuning time\n",
    "tuning_times\n",
    "\n",
    "\n",
    "headings = [\n",
    "    'Model',\n",
    "    'Accuracy without hyperparameter tuning (%)',\n",
    "    'Accuracy after hyperparameters tuning (%)',\n",
    "    'Accuracy improvement (%)',\n",
    "    'Training time (s)',\n",
    "    'Hyperparameter tuning time (s)',\n",
    "]\n",
    "\n",
    "data = [\n",
    "    models,\n",
    "    accuracies,\n",
    "    tuned_accuracies,\n",
    "    accuracy_improvement,\n",
    "    [training_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "    [tuning_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "]\n",
    "\n",
    "# round all numbered data\n",
    "data = [[round(e, 4) for e in col] if type(col[0]) is not str else col for col in data]\n",
    "\n",
    "data = np.array(data).transpose()\n",
    "\n",
    "print(tabulate.tabulate(data, headers=headings))\n",
    "\n",
    "# draw conclusions about different models (which ones benefited the most from hyper-tuning, speed, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c95066",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "## **Results**\n",
    "\n",
    "| Model | Accuracy without hyperparameter tuning |95 % CI| Accuracy after hyperparameter tuning |95% CI| Accuracy Improvement (%)| Training time (s) | Hyperparameter tuning time (s)|\n",
    "|-------|--------|---------|----------|-----------|------------|--------|-------|\n",
    "|Logistic Regression|0.8182|---|0.8155|---|-3.3|0.0529|5.3054|\n",
    "|KNN|0.7995|----|0.8164|-----|2.1|0.0039|16.8341|\n",
    "|Decision Tree|0.785|------|0.8368|------|6.6|0.0802|4.9904|\n",
    "|SVM|0.8564|------|0.8582|-------|0.21|1.257|84|\n",
    "|Random Forest|0.8522|------|/|/|/|1.02|/|\n",
    "|XGboost|0.8564|-------|0.86|-------|0.42|0.268|21|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f272ab3",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 1000px; font-family: 'Georgia', serif; font-size: 14px; line-height: 1.6;\">\n",
    "\n",
    "\n",
    "## **Comments**\n",
    "\n",
    "### <u>**Base Models**</u>\n",
    "From the above table, we note that out off the base models, the logistic regression performed the best with an accuracy score of 81.8 %. Then came the KNN method and finally the Decision Tree with accuracies of 79.95% and 78.5% respectively. \n",
    "\n",
    "\n",
    "\n",
    "#### **After hyperparameter tuning** \n",
    "After hyperparameter tuning, the Decision Tree method achieved both the overall highest accuracy of all base models with 83.68% \n",
    "and the greatest improvement in accuracy (6.6%). A surprising result comes from the Logistic Regression, who displayed a decrease of 3.3% in accuracy after tuning the hyperparameters.\n",
    "\n",
    "\n",
    "#### **Tuning time** \n",
    "Overall, it is also the Decision Tree model that displayed the lowest hyperparameter tuning time with 4.99 seconds compared to 5.3 seconds \n",
    "for the Logistic Regression and a much higher value of 16.8 seconds for KNN.\n",
    "\n",
    "### <u>**Advanced Models**</u>\n",
    "\n",
    "All three of the  (untuned) advanced models performed better than the base models before and after hyperparameter tuning. They all present similar accuracy scores with SVM and XGboost achieving a slightly higher (and identical) accuracy of 85.64 %. \n",
    "\n",
    "We checked the confusion matrix for XGboost and SVM and noticed that they had different numbers of correct predictions for class 0 and class 1 (has the client subscribed a term deposit?) but overall achieved the same number of total correct predictions, which explains one they achieved identical accuracy scores.\n",
    "\n",
    "#### **After hyperparameter tuning**\n",
    "\n",
    "We decide to tuned the SVM and XGBoost models as they presented the highest accuracy of the advanced models. XGBoost achieved the higher accuracy score increase of the 2 (0.42%), with a final accuracy of 86%. It also had the faster hyperparameter tuning time with 21 seconds compared to 84 seconds for SVM (only improving accuracy by 0.21%)\n",
    "\n",
    "### <u>**Conclusion**</u>\n",
    "\n",
    "We conclude that we should use the more advanced prediction models for this problem as they all presented higher accuracy scores than the base models. We would favour the XGboost model as it presented the highest overall accuracy of all models (tuned and untuned) and as tuning was faster for that specifc model. \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f113c",
   "metadata": {},
   "source": [
    "<div style= \"font-family: 'Georgia', serif;\" >\n",
    "\n",
    "\n",
    "## **Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Load test dataset\n",
    "\n",
    "test_set = pd.read_pickle(COMPETITION_DATA_PATH)\n",
    "\n",
    "print(test_set.columns)\n",
    "\n",
    "# make predictions about this using the best method\n",
    "\n",
    "# save final model (in notes)\n",
    "# save predictions in a file (pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
