{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b926ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zavier Morales\n",
    "# Edouard Mason\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define global variables & import data\n",
    "\n",
    "RANDOM_STATE_ID = 100577770\n",
    "\n",
    "TRAINING_DATA_PATH = Path('dataset', 'bank_06.pkl')\n",
    "COMPETITION_DATA_PATH = Path('dataset', 'bank_competition.pkl')\n",
    "\n",
    "training_times = {}\n",
    "tuning_times = {}\n",
    "prediction_times = {}\n",
    "\n",
    "raw_data = pd.read_pickle(TRAINING_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcefc7",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c6ca3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      " (11000, 17)\n",
      "\n",
      "First few rows:\n",
      "    age         job  marital  education default  balance housing loan  contact  \\\n",
      "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
      "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
      "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
      "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
      "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
      "\n",
      "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
      "0    5   may      1042         1     -1         0  unknown     yes  \n",
      "1    5   may      1467         1     -1         0  unknown     yes  \n",
      "2    5   may      1389         1     -1         0  unknown     yes  \n",
      "3    5   may       579         1     -1         0  unknown     yes  \n",
      "4    5   may       673         2     -1         0  unknown     yes  \n",
      "\n",
      "List of columns:\n",
      " Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'deposit'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Target variable: 0    yes\n",
      "1    yes\n",
      "2    yes\n",
      "3    yes\n",
      "4    yes\n",
      "Name: deposit, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset:\\n\", raw_data.shape)\n",
    "print(\"\\nFirst few rows:\\n\",raw_data.head())\n",
    "print(\"\\nList of columns:\\n\",raw_data.columns)\n",
    "print(\"\\n\\n\\nTarget variable:\",raw_data['deposit'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1188cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            76\n",
      "job            12\n",
      "marital         3\n",
      "education       4\n",
      "default         2\n",
      "balance      3783\n",
      "housing         2\n",
      "loan            2\n",
      "contact         3\n",
      "day            31\n",
      "month          12\n",
      "duration     1423\n",
      "campaign       36\n",
      "pdays         472\n",
      "previous       34\n",
      "poutcome        4\n",
      "deposit         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Cardinality of variables\n",
    "unique_counts = raw_data.nunique()\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "012a3f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the DataFrame:\n",
      "\n",
      " Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'deposit', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
      "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
      "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
      "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
      "       'education_primary', 'education_secondary', 'education_tertiary',\n",
      "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
      "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
      "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
      "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
      "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
      "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
      "       'poutcome_unknown'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "\n",
      "    age  balance  day  duration  campaign  pdays  previous deposit  job_admin.  \\\n",
      "0   59     2343    5      1042         1     -1         0     yes           1   \n",
      "1   56       45    5      1467         1     -1         0     yes           1   \n",
      "2   41     1270    5      1389         1     -1         0     yes           0   \n",
      "3   55     2476    5       579         1     -1         0     yes           0   \n",
      "4   54      184    5       673         2     -1         0     yes           1   \n",
      "\n",
      "   job_blue-collar  ...  month_jun  month_mar  month_may  month_nov  \\\n",
      "0                0  ...          0          0          1          0   \n",
      "1                0  ...          0          0          1          0   \n",
      "2                0  ...          0          0          1          0   \n",
      "3                0  ...          0          0          1          0   \n",
      "4                0  ...          0          0          1          0   \n",
      "\n",
      "   month_oct  month_sep  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "0          0          0                 0               0                 0   \n",
      "1          0          0                 0               0                 0   \n",
      "2          0          0                 0               0                 0   \n",
      "3          0          0                 0               0                 0   \n",
      "4          0          0                 0               0                 0   \n",
      "\n",
      "   poutcome_unknown  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "\n",
      "Missing values per column:\n",
      "\n",
      " age                    0\n",
      "balance                0\n",
      "day                    0\n",
      "duration               0\n",
      "campaign               0\n",
      "pdays                  0\n",
      "previous               0\n",
      "deposit                0\n",
      "job_admin.             0\n",
      "job_blue-collar        0\n",
      "job_entrepreneur       0\n",
      "job_housemaid          0\n",
      "job_management         0\n",
      "job_retired            0\n",
      "job_self-employed      0\n",
      "job_services           0\n",
      "job_student            0\n",
      "job_technician         0\n",
      "job_unemployed         0\n",
      "job_unknown            0\n",
      "marital_divorced       0\n",
      "marital_married        0\n",
      "marital_single         0\n",
      "education_primary      0\n",
      "education_secondary    0\n",
      "education_tertiary     0\n",
      "education_unknown      0\n",
      "default_no             0\n",
      "default_yes            0\n",
      "housing_no             0\n",
      "housing_yes            0\n",
      "loan_no                0\n",
      "loan_yes               0\n",
      "contact_cellular       0\n",
      "contact_telephone      0\n",
      "contact_unknown        0\n",
      "month_apr              0\n",
      "month_aug              0\n",
      "month_dec              0\n",
      "month_feb              0\n",
      "month_jan              0\n",
      "month_jul              0\n",
      "month_jun              0\n",
      "month_mar              0\n",
      "month_may              0\n",
      "month_nov              0\n",
      "month_oct              0\n",
      "month_sep              0\n",
      "poutcome_failure       0\n",
      "poutcome_other         0\n",
      "poutcome_success       0\n",
      "poutcome_unknown       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encoding object-type variables\n",
    "df_encoded = pd.get_dummies(raw_data, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome'])\n",
    "\n",
    "#Converting all boolean columns to integers (1 for True, 0 for False)\n",
    "df_encoded[df_encoded.select_dtypes(include=['bool']).columns] = df_encoded.select_dtypes(include=['bool']).astype(int)\n",
    "print(\"\\nColumns in the DataFrame:\\n\\n\",df_encoded.columns)\n",
    "print(\"\\n\\nFirst few rows of the DataFrame:\\n\\n\",df_encoded.head())\n",
    "\n",
    "#Checking the number of missing values per column\n",
    "missing_values = df_encoded.isnull().sum()\n",
    "print(\"\\nMissing values per column:\\n\\n\", missing_values)   #We get 0 for each column so we have no missing values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e326819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8203\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where pdays == -1\n",
    "count_minus1 = (raw_data['pdays'] == -1).sum()\n",
    "\n",
    "print(count_minus1)\n",
    "\n",
    "# We see that there are 8203 where pdays = -1, that is where we have no info or contact. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57bb73b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.0\n"
     ]
    }
   ],
   "source": [
    "# We create a new binary column with value = 1 if previously contacted and 0 if pdays = -1 (no previous contact)\n",
    "df_encoded[\"prev_contacted\"] = (df_encoded[\"pdays\"] != -1).astype(int)\n",
    "# We only calculate the median on values greater than -1\n",
    "known_pdays = df_encoded.loc[df_encoded['pdays'] != -1, \"pdays\"]\n",
    "median_pdays = known_pdays.median()\n",
    "print(median_pdays)\n",
    "\n",
    "# We replace all -1 values with the median of the know_pdays\n",
    "df_encoded['pdays_duration'] = df_encoded['pdays'].replace(-1, median_pdays)\n",
    "\n",
    "# We drop the original pdays variable\n",
    "df_encoded.drop('pdays', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a5e5fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11157    182\n",
      "11158    182\n",
      "11159    182\n",
      "11160    172\n",
      "11161    182\n",
      "Name: pdays_duration, dtype: int64\n",
      "       age  balance  day  duration  campaign  previous deposit  job_admin.  \\\n",
      "11157   33        1   20       257         1         0      no           0   \n",
      "11158   39      733   16        83         4         0      no           0   \n",
      "11159   32       29   19       156         2         0      no           0   \n",
      "11160   43        0    8         9         2         5      no           0   \n",
      "11161   34        0    9       628         1         0      no           0   \n",
      "\n",
      "       job_blue-collar  job_entrepreneur  ...  month_may  month_nov  \\\n",
      "11157                1                 0  ...          0          0   \n",
      "11158                0                 0  ...          0          0   \n",
      "11159                0                 0  ...          0          0   \n",
      "11160                0                 0  ...          1          0   \n",
      "11161                0                 0  ...          0          0   \n",
      "\n",
      "       month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
      "11157          0          0                 0               0   \n",
      "11158          0          0                 0               0   \n",
      "11159          0          0                 0               0   \n",
      "11160          0          0                 1               0   \n",
      "11161          0          0                 0               0   \n",
      "\n",
      "       poutcome_success  poutcome_unknown  prev_contacted  pdays_duration  \n",
      "11157                 0                 1               0             182  \n",
      "11158                 0                 1               0             182  \n",
      "11159                 0                 1               0             182  \n",
      "11160                 0                 0               1             172  \n",
      "11161                 0                 1               0             182  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded['pdays_duration'].tail())\n",
    "print(df_encoded.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5a665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "deposit      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8104d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We convert yes to 1 and no to 0 for the target 'deposit'\n",
    "df_encoded[\"deposit\"] = df_encoded[\"deposit\"].map({\"yes\": 1, \"no\": 0}) #Used AI to convert yes to 1 and no to 0 in the target column 'deposit'\n",
    "\n",
    "y = df_encoded[\"deposit\"]\n",
    "X = df_encoded.drop(\"deposit\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE_ID)\n",
    "\n",
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'previous', 'pdays_duration']\n",
    "cat_cols = [col for col in df_encoded.columns if col not in num_cols and col != 'deposit']  # Used AI to create the loop selecting all columns that are not in num_cols and are not 'deposit'\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols), \n",
    "        ('cat', 'passthrough', cat_cols) \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4ee72",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75348c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "start_time = time.time()\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "training_times[\"lr\"] = time.time() - start_time\n",
    "\n",
    "y_pred_log = logreg.predict(X_test_processed)\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(accuracy_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14a571",
   "metadata": {},
   "source": [
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9ce2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7995454545454546\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(X_train_processed, y_train)\n",
    "training_times[\"knn\"] = time.time() - start_time\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_processed)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ac996",
   "metadata": {},
   "source": [
    "### **Tree** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e83636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "tree = tree.fit(X_train_processed, y_train)\n",
    "training_times[\"tree\"] = time.time() - start_time\n",
    "\n",
    "y_pred_tree = tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0942093",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efa349",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63ec4dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'C': np.float64(4.281332398719396), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score (Random Search): 0.8185949201235179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid_lr = {\n",
    "    'C' : np.logspace(-4, 4, 20), \n",
    "    'penalty': ['l2'],             \n",
    "    'solver': ['lbfgs', 'liblinear'] \n",
    "}\n",
    "\n",
    "logistic = LogisticRegression(random_state=RANDOM_STATE_ID, max_iter=1000)\n",
    "\n",
    "# Find best hyperparameters using RandomizedSearchCV\n",
    "grid_search = GridSearchCV(logistic, param_grid=param_grid_lr, \n",
    "                                     cv=5,\n",
    "                                   scoring='f1',\n",
    "                                    n_jobs=1\n",
    ")\n",
    "\n",
    "# Train the model with best hyperparameters\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "tuning_times[\"lr\"] = time.time() - start_time\n",
    "best_params= grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02e18705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8154545454545454\n",
      "{'lr': 5.3054118156433105}\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy over entire training set\n",
    "tuned_lr = grid_search.best_estimator_\n",
    "y_pred_tuned = tuned_lr.predict(X_test_processed)\n",
    "accuracy_tuned_lr = accuracy_score(y_pred_tuned,y_test )\n",
    "\n",
    "print(accuracy_tuned_lr)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5f712",
   "metadata": {},
   "source": [
    "### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e042932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Best Score (Random Search): 0.8103409090909091\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "grid_search_knn = GridSearchCV(knn, param_grid=param_grid_knn, \n",
    "                                cv=5, scoring=\"accuracy\", \n",
    "                                n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_knn.fit(X_train_processed, y_train)\n",
    "tuning_times[\"knn\"] = time.time() - start_time\n",
    "best_params= grid_search_knn.best_params_\n",
    "best_score = grid_search_knn.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e905c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163636363636364\n",
      "{'lr': 5.3054118156433105, 'knn': 16.83409810066223}\n"
     ]
    }
   ],
   "source": [
    "tuned_knn = grid_search_knn.best_estimator_\n",
    "y_pred_tuned = tuned_knn.predict(X_test_processed)\n",
    "accuracy_tuned_knn = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tuned_knn)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bf047",
   "metadata": {},
   "source": [
    "### **Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39f993f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Search): {'criterion': 'gini', 'max_depth': 13, 'min_samples_leaf': 18, 'min_samples_split': 3}\n",
      "Best Score (Random Search): 0.8294310648952874\n"
     ]
    }
   ],
   "source": [
    "param_dist_tree = {\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20)\n",
    "}\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "#Tuning using RandomizedSearchCV\n",
    "random_search_tree = RandomizedSearchCV(tree, param_distributions=param_dist_tree, \n",
    "                                   cv=3, scoring='accuracy',\n",
    "                                   n_iter=50, random_state=RANDOM_STATE_ID,\n",
    "                                   n_jobs=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search_tree.fit(X_train_processed, y_train)\n",
    "tuning_times[\"tree\"] = time.time() - start_time\n",
    "best_params= random_search_tree.best_params_\n",
    "best_score = random_search_tree.best_score_\n",
    "\n",
    "print(f\"Best Parameters (Random Search): {best_params}\")\n",
    "print(f\"Best Score (Random Search): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb835659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8368181818181818\n",
      "{'lr': 5.3054118156433105, 'knn': 16.83409810066223, 'tree': 4.990444898605347}\n"
     ]
    }
   ],
   "source": [
    "tuned_tree = random_search_tree.best_estimator_\n",
    "y_pred_tuned = tuned_tree.predict(X_test_processed)\n",
    "\n",
    "accuracy_tree_tuned = accuracy_score(y_pred_tuned, y_test)\n",
    "\n",
    "print(accuracy_tree_tuned)\n",
    "print(tuning_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4ace0",
   "metadata": {},
   "source": [
    "## **Advanced Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b41ab",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81d8fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 0.8563636363636363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "svm_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_pred_svm, y_test)\n",
    "\n",
    "print(\"SVM Accuracy Score:\", accuracy_svm)\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e245b",
   "metadata": {},
   "source": [
    "### **Random Forest Classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e65f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy score: 0.8522727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE_ID)\n",
    "\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_rf= rf.predict(X_test_processed)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
    "\n",
    "print(\"Random Forest Accuracy score:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679d88a",
   "metadata": {},
   "source": [
    "#### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a236e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score: 0.8563636363636363\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    objective='binary:logistic', \n",
    "    random_state=RANDOM_STATE_ID\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_pred_xgb, y_test)\n",
    "\n",
    "print(\"XGBoost accuracy score:\", accuracy_xgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4f432",
   "metadata": {},
   "source": [
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2c6b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model                  Accuracy without hyperparameter tuning (%)    Accuracy after hyperparameters tuning (%)    Accuracy improvement (%)    Training time (s)    Hyperparameter tuning time (s)\n",
      "-------------------  --------------------------------------------  -------------------------------------------  --------------------------  -------------------  --------------------------------\n",
      "Logistic Regression                                        0.8182                                       0.8155                     -0.0033               0.0529                            5.3054\n",
      "KNN                                                        0.7995                                       0.8164                      0.021                0.0039                           16.8341\n",
      "Decision Tree                                              0.785                                        0.8368                      0.066                0.0802                            4.9904\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate\n",
    "import tabulate\n",
    "\n",
    "## Results to report (in a table):\n",
    "\n",
    "# by model (KNN, LR, DT)\n",
    "models = ['Logistic Regression', 'KNN', 'Decision Tree']\n",
    "\n",
    "# confidence intervals (RMSE)\n",
    "#  before hyperparameter tuning\n",
    "accuracies = [accuracy_log, accuracy_knn, accuracy_tree]\n",
    "#  after hyperparameter tuning\n",
    "tuned_accuracies = [accuracy_tuned_lr, accuracy_tuned_knn, accuracy_tree_tuned]\n",
    "# accuracy improvement\n",
    "accuracy_improvement = [(tuned_accuracies[idx] - acc) / acc for idx, acc in enumerate(accuracies)]\n",
    "\n",
    "# training time\n",
    "training_times\n",
    "# hyperparam tuning time\n",
    "tuning_times\n",
    "\n",
    "\n",
    "headings = [\n",
    "    'Model',\n",
    "    'Accuracy without hyperparameter tuning (%)',\n",
    "    'Accuracy after hyperparameters tuning (%)',\n",
    "    'Accuracy improvement (%)',\n",
    "    'Training time (s)',\n",
    "    'Hyperparameter tuning time (s)',\n",
    "]\n",
    "\n",
    "data = [\n",
    "    models,\n",
    "    accuracies,\n",
    "    tuned_accuracies,\n",
    "    accuracy_improvement,\n",
    "    [training_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "    [tuning_times[key] for key in ['lr', 'knn', 'tree']],\n",
    "]\n",
    "\n",
    "# round all numbered data\n",
    "data = [[round(e, 4) for e in col] if type(col[0]) is not str else col for col in data]\n",
    "\n",
    "data = np.array(data).transpose()\n",
    "\n",
    "print(tabulate.tabulate(data, headers=headings))\n",
    "\n",
    "# draw conclusions about different models (which ones benefited the most from hyper-tuning, speed, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f113c",
   "metadata": {},
   "source": [
    "## **Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e5d377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Load test dataset\n",
    "\n",
    "test_set = pd.read_pickle(COMPETITION_DATA_PATH)\n",
    "\n",
    "print(test_set.columns)\n",
    "\n",
    "# make predictions about this using the best method\n",
    "\n",
    "# save final model (in notes)\n",
    "# save predictions in a file (pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
